<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="utf-8">
    <title>Client Camera Emotion Detection</title>
    <style>
        body {
            background: #111;
            color: #eee;
            font-family: Arial;
            text-align: center;
            padding-top: 20px;
        }
        h2 { color: #0f0; }
        #cam, #result {
            border: 2px solid #444;
            border-radius: 8px;
            margin: 10px;
        }
    </style>
</head>
<body>

<h2>ðŸŽ¥ Client Camera â†’ Server Inference â†’ Live Result</h2>

<!-- Client Camera -->
<video id="cam" autoplay playsinline width="480"></video><br>

<!-- Server Output -->
<img id="result" width="480" alt="processed result will appear here">

<script>
    const video = document.getElementById("cam");
    const result = document.getElementById("result");

    async function startCamera() {
        try {
            let stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
        } catch (err) {
            alert("Cannot access camera: " + err);
        }
    }

    // Auto-correct ws:// or wss:// depending on deployment
    const wsProtocol = location.protocol === "https:" ? "wss" : "ws";
    const ws = new WebSocket(wsProtocol + "://" + window.location.host + "/ws");

    ws.onmessage = (msg) => {
        // server returns base64-encoded frame
        result.src = "data:image/jpeg;base64," + msg.data;
    };

    function capture() {
        if (video.videoWidth === 0) return;

        let canvas = document.createElement("canvas");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        let ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0);

        let base64 = canvas.toDataURL("image/jpeg").split(",")[1];
        ws.send(base64);
    }

    // Send 10 fps to server
    setInterval(capture, 100);

    startCamera();
</script>

</body>
</html>
